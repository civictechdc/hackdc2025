# Hive-partitioned Parquet

**Team:** Jay Qi  
**Hackathon:** Civic Hack DC 2025  
**Challenge:** Data Accessibility & Cost / Data Quality & Derived Layers

## Problem Statement

Write out data as Hive-partitioned Parquet files for fast and efficient queries using DuckDB.

If applied to the data in S3, users can query directly from S3 much faster and more efficiently. This data format optimization enables better performance for large-scale regulatory data analysis by organizing data in a columnar format with efficient partitioning.

**Links:** [GitHub Repository](https://github.com/jayqi/mirrulations-hive-partitioned-parquet)

## üõ†Ô∏è Tech Stack

- Backend: Python data processing
- Format: Hive-partitioned Parquet
- Query Engine: DuckDB
- Storage: S3-compatible storage

## Team Members

- **Jay Qi**
