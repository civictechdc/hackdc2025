## Evaluator Information

**Name:** Melanie Kourbage
**Affiliation:** APHL
**Email:** <melanie.kourbage@aphl.org>

## Project Evaluations

<!-- Copy this template for each project you're evaluating -->

### Project: rules-talk

**Team:** \[Team Name]

**Scores (0–5 scale):**

* Impact & Relevance (20%): 4/5
* Novelty (20%): 4/5
* Amplification (15%): 4/5
* Open Source Practices (15%): 5/5
* Usability & Design (15%): 5/5
* Continuity Potential (15%): 3/5

**Comments:**

Info on sentiment, flavor of comments, serves as a pulse check: are most people in favor of this rule, or not?
The instructions for how to use the tool are very detailed, but I'm a totally non-technical user. I would likely still rely on one of the programmers on my team to pull this info for me, but the lift would be minimal with them with these instructions.
I would like report to include who submitted the comments.
Header includes # of comments - could you also tally how many pos, how many neg?
National Provider Directory is a GREAT first use case!

---

### Project: Entity Resolution

**Team:** \[Team Name]

**Scores (0–5 scale):**

* Impact & Relevance (20%): 5/5
* Novelty (20%): 3/5
* Amplification (15%): 5/5
* Open Source Practices (15%): 5/5
* Usability & Design (15%): 3/5
* Continuity Potential (15%): 3/5

**Comments:**

Identifying the submitting org may be challenging depending on the format of the comments that were submitted. In the example, Peg identified as both CMS and QUA, Inc., even though Pam was responding to a CMS proposed rule. Would like to see more examples of how this could be leveraged successfully. I would use this to compare against a list of our member organizations (public health labs), our partner organizations, and our key industry partners to see which ones submitted a response.
I see a lot of potential here. The lower scores are only because I couldn't find the documentation for what comes next and I'm not clear on how you're identifying the org info from the comment
---

### Project: within-docket-dataset

**Team:** \[Team Name]

**Scores (0–5 scale):**

* Impact & Relevance (20%): 5/5
* Novelty (20%): 3/5
* Amplification (15%): 5/5
* Open Source Practices (15%): 5/5
* Usability & Design (15%): 2/5
* Continuity Potential (15%): 2/5

**Comments:**

The initial process flow looks promising. I look forward to seeing more as you continuing to build out this tool! Figuring out the impact of the comments on the final rule is so valuable! It can take a lot of subject matters experts a lot of time to put together thoughtful comments. But is this a valuable use of our time? Does it make a difference? We have public policy and government affairs staff that are also working on building relationships with these agencies, but being able to study which comments are making an impact and how they're framed would be invaluable.

*By submitting this form, I confirm that my evaluations are fair and based on the projects' merits according to the stated criteria.*
